---
title: "Day 3 Problem Set"
author: "Cecilia Sui"
date: "1/12/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Day 3 Outline:
1. Functions & Arguments 
2. Control Statements (if, if-else, for, while)
3. Bootstrapping


# Functions 

1. Write an R function, **choose.members(n,c,p)**, that returns the number of
   ways to choose members from an organization of **p** people to serve on an
   executive committee consisting of **n** "named positions" (e.g., president,
   vice-president, treasurer, and so on...), and **c** at-large members of equal
   rank, as the sample output below suggests. Hint: remember during the last
   week of class in Math Modeling when we covered combination and permutation.
   You might want to check out the help pages for the functions: **factorial()**
   and **choose()**.

```{r}
choose.members <- function(n, c, p) {
  return(factorial(n) * choose(p, n) * choose(p - n, c))
}
choose.members(3, 3, 10)
choose.members(4, 4, 12)
```


2. Write a function **is.even(n)** in R that returns TRUE when n is even and
   FALSE otherwise. Then, using **is.even(n)**, write a function **evens.in(v)**
   that returns a vector comprised of the even integers in a vector v of
   integers. You can use the modulus operator that you encountered yesterday
   when subsetting the dataframes.

```{r}
is.even <- function(n) {
  return(n %% 2 == 0)
}

evens.in <- function(v) {
  return(v[is.even(v)])
}

evens.in(1:20)
```

3. Describe what the following function does in the context of statistics. Be as
   specific as you can, without knowing the value of data. Make sure you
   understand every operator and every function used in every line of the code.

```{r eval = FALSE}
mystery <- function(data) {
  a <- mean(data) - 2 * sd(data) # Finds the value that is 2 standard deviations below the mean
  b <- mean(data) + 2 * sd(data) # Finds the value that is 2 standard deviations above the mean
  is.in <- (data > a) & (data < b) # Checks to see the data that is within 2 standard deviations of the mean
  print(sum(!is.in)) # Prints the sum of values that are within the bounds
  return(data[is.in]) # Return the values that are in the bounds previously defined
}
```

4. Assume that a data set is stored in the vector **data** in R. You do not need
   the actual values for **data** for this question. Write a function
   **skewness(data)** that calculates the skewness index $I =
   \frac{3(\bar{x}-Q_2)}{s}$ of the data set and returns either "The data is
   significantly skewed" or "The data is not significantly skewed" as
   appropriate. If the skewness is greater than 1, it is skewed.

```{r eval = FALSE}
skewness <- function(data) {
  I <- 3 * (mean(data) - median(data) / sd(data))
  if (I < 1) {
    print("This data is not significantly skewed")
  } else {
    print("This data is significantly skewed")
  }
}
```

# Control Statements

1. What is the output of the following code block? How many Win's and Lose's
   will it print? What numbers are being compared each time the loop is
   iterated?

```{r eval = FALSE}
# Checks to see if the first value of the vector is greater than the second
# value in the vector.

# 3 wins

# The first and second values of the inner vectors
matches <- list(c(2, 1), c(5, 2), c(6, 3))
for (match in matches) {
  if (match[1] > match[2]) {
    print("Win")
  } else {
    print("Lose")
  }
}
```


2. Simulating an Opinion Poll

You can also use the **sample()** function to simulate an opinion poll. Suppose
that you want to ask an opinion poll on whether people like eating barbeque. The
two responses that you allow are “Yes” or “No”. It is often convenient to
represent “Yes” as 1 and “No” as 0, for reasons that will be clear in a moment.
Since this is St. Louis, let's assume that 75% of people like eating barbeque.

* 2.1 Simulate what would happen if you randomly sampled 20 individuals and
  asked that question. Use the help page when assigning the probabilities.
```{r}
set.seed(12345)

poll_bbq <- sample(0:1, 20, replace = TRUE, prob = c(0.25, 0.75))
```

* 2.2 Take the mean of the sample. Write your code to simulate the opinion poll
  10 times and calculates the proportion who like barbeque.
```{r}
mean(poll_bbq)

for (i in 1:10) {
  poll_bbq <- sample(0:1, 20, replace = TRUE, prob = c(0.25, 0.75))
  print(mean(poll_bbq))
}
```

3. **FiveThirtyEight** calculates that President Biden's approval rating,
   accounting for each poll's quality, tendency, sample size and partisan lean,
   is around 45%. The number might be a little bit different today, but lets go
   ahead with it nevertheless.

* 3.1 Simulate drawing an opinion poll of 25 people. Repeat this 50 times. Then
  simulate drawing 100 people, and repeat this 50 times. Then simulate drawing
  1000 people, and repeat this 50 times. Make sure to store the mean, median,
  variance and standard deviations to use for the following questions.
```{r}
bootstrap_poll <- function(n = 25) {
  mean <- c()
  var <- c()
  median <- c()
  sd <- c()

  for (i in 1:50) {
    # Create sample of 0s and 1s to show the polls.
    sample <- sample(
      x = c(0, 1),
      size = n,
      replace = TRUE,
      prob = c(0.55, 0.45)
    )
    # Impute the values to the vectors defined before
    mean[i] <- mean(sample)
    var[i] <- var(sample)
    median[i] <- median(sample)
    sd[i] <- sd(sample)
  }
  # Put the results into a list
  results <- list(
    mean = mean,
    variance = var,
    median = median,
    sd = sd
  )

  return(results)
}

# Poll 1
poll_1 <- bootstrap_poll()
poll_1

# Poll 2
poll_2 <- bootstrap_poll(n = 100)
poll_2

# Poll 3
poll_3 <- bootstrap_poll(n = 1000)
poll_3
```

* 3.2 How does the central tendency of the survey results change as the sample
  size increases?
```{r}
hist(poll_1[[1]]) # Show histogram of the means of first poll
hist(poll_2[[1]]) # Show histogram of the means of second poll
hist(poll_3[[1]]) # Show histogram of the means of third poll

# Mean goes towards the probabilities that we defined previously
```

* 3.3 How does the spread of the survey results change as the sample size
  increases?
```{r}
quantile(poll_1[[1]]) # Show quantiles of the means of first poll
quantile(poll_2[[1]]) # Show quantiles of the means of second poll
quantile(poll_3[[1]]) # Show quantiles of the means of third poll

# The spread of the data gets narrower as the sample size increases
```

# Bootstrapping with Real Data

The bootstrap method exploits randomness in our sample (which, when it comes
down to it, is the source of parameter uncertainty).

The process is as follows:

1. Draw a random sample with replacement of the data of the same size as the
   data
2. Calculate quantity of interests (sample means, variance, models)
3. Repeat 1 and 2 n times.
4. Get mean and variance of quantity of interests from empirical distribution of
   samples.

Essentially, we are pulling ourselves up by our own sample’s bootstraps to
estimate the population. Note that this relies on our sample being a random
sample from the population, or at least fairly close. When the assumption is not
sufficiently satisfied, the bootstarpped values fail to serve as good estimates.


We will use the **worldTFR** dataset again, since you are probably super
familiar with it by now!

1. Load the dataset as worldTFR. Draw a random sample with replacement of the
   TFR values of the same size as the dataset. Save it to an R object. Make sure
   you exclude NA's in the TFR column if there are any.
```{r}
worldTFR <- read.csv("worldTFR.csv") # Load in data
TFR <- worldTFR$TFR[!is.na(worldTFR$TFR)] # Save TFR to a vector with NAs removed
samp <- sample(TFR, length(TFR), replace = TRUE) # Sample TFR with replacement
```

2. Calculate the **mean** of your sampled TFRs. Compare it to the "true" TFR.
```{r}
mean(TFR)
mean(samp)
```

3. Write a **for** loop that repeats the sampling process 5000 times. Remember
   to set your seed for replication. You need to create a vector that stores all
   the means. Inside the **for** loop, you would need to save each mean to the
   vector. After running the loop, take the average of all the 5000 means, and
   compare it to the "true" mean. What is the variance of your means?

```{r}
set.seed(12345) # set the seed for randomization

TFR_means <- c()

for (i in 1:5000) {
  samp <- sample(TFR, length(TFR), replace = TRUE) # Sample TFR with replacement
  TFR_means[i] <- mean(samp)
}
```

4. Can you do Q3 with a **while** loop? Report the average and variance of the
   means.
```{r}
i <- 1
while (i < 5001) {
  samp <- sample(TFR, length(TFR), replace = TRUE) # Sample TFR with replacement
  TFR_means[i] <- mean(samp)
  i <- i + 1 # add one to our test condition so it will eventually become FALSE
}
```

5. Now let's bootstrap the variance of TFR. Similar to Q3, but instead of
   calculating the means for each sample, find the variance for each sample and
   store them into a vector called **vars**. Remember to first initialize the
   vector before storing values.
```{r}
vars <- c()

for (i in 1:5000) {
  samp <- sample(TFR, length(TFR), replace = TRUE) # Sample TFR with replacement
  vars[i] <- mean(samp)
}
```
